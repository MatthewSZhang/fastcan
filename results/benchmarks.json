{
    "fastcan.FastCanBenchmark.peakmem_fit": {
        "code": "class FastCanBenchmark:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "fastcan.FastCanBenchmark.peakmem_fit",
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'"
            ]
        ],
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "2bff765ceeba8ebc662b40d48a34ddfce3f9cb16bc048bc6e29b325c0710512a"
    },
    "fastcan.FastCanBenchmark.peakmem_transform": {
        "code": "class FastCanBenchmark:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "fastcan.FastCanBenchmark.peakmem_transform",
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'"
            ]
        ],
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "ccc7a4f9ab9c2cfb2e82498a9466498ca9b2fb7c395e9f79c674074bb4018c00"
    },
    "fastcan.FastCanBenchmark.time_fit": {
        "code": "class FastCanBenchmark:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "min_run_count": 2,
        "name": "fastcan.FastCanBenchmark.time_fit",
        "number": 0,
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "ae78b5ad8412ea9ee1a07ff7915c371a2bcc7c71e2a074520211654c4b317b6a",
        "warmup_time": -1
    },
    "fastcan.FastCanBenchmark.time_transform": {
        "code": "class FastCanBenchmark:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "min_run_count": 2,
        "name": "fastcan.FastCanBenchmark.time_transform",
        "number": 0,
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "f567e4f5fce03709f2a8ba3b3e0989b74b5dcb32c2b83c7a3a2880f978e89f74",
        "warmup_time": -1
    },
    "fastcan.FastCanBenchmark.track_test_score": {
        "code": "class FastCanBenchmark:\n    def track_test_score(self, *args):\n        task, _ = args\n        X_t = self.estimator.transform(self.X_val)\n        if task == \"classif\":\n            clf = LinearDiscriminantAnalysis()\n            clf.fit(X_t, self.y_val)\n            return float(clf.score(X_t, self.y_val))\n        else:\n            reg = LinearRegression()\n            reg.fit(X_t, self.y_val)\n            return float(reg.score(X_t, self.y_val))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "fastcan.FastCanBenchmark.track_test_score",
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'"
            ]
        ],
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "track",
        "unit": "unit",
        "version": "cb7d948ad21f20387c2971eae1703cf93c1f12021a23768380d3c5466ca156fb"
    },
    "fastcan.FastCanBenchmark.track_train_score": {
        "code": "class FastCanBenchmark:\n    def track_train_score(self, *args):\n        task, _ = args\n        X_t = self.estimator.transform(self.X)\n        if task == \"classif\":\n            clf = LinearDiscriminantAnalysis()\n            clf.fit(X_t, self.y)\n            return float(clf.score(X_t, self.y))\n        else:\n            reg = LinearRegression()\n            reg.fit(X_t, self.y)\n            return float(reg.score(X_t, self.y))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass FastCanBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            _, alg = params\n            X, _, y, _ = self.make_data(params)\n    \n            if alg == \"h\":\n                eta = False\n            else:\n                eta = True\n            estimator = FastCan(\n                n_features_to_select=20,\n                eta=eta,\n            )\n            estimator.fit(X, y)\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "fastcan.FastCanBenchmark.track_train_score",
        "param_names": [
            "task",
            "alg"
        ],
        "params": [
            [
                "'classif'",
                "'reg'"
            ],
            [
                "'h'",
                "'eta'"
            ]
        ],
        "setup_cache_key": "fastcan:21",
        "timeout": 500,
        "type": "track",
        "unit": "unit",
        "version": "fd8a3aceddb21b108152ae90e36f9021df59130b996bf33156f1b75479f1d12e"
    },
    "narx.NARXBenchmark.peakmem_fit": {
        "code": "class NARXBenchmark:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "narx.NARXBenchmark.peakmem_fit",
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "196e70bf8599ddf97952a57e076a2e6fd14fb642bef7afb8fcd32c52b76901e5"
    },
    "narx.NARXBenchmark.peakmem_predict": {
        "code": "class NARXBenchmark:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X, self.y[: self.max_delay])\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "narx.NARXBenchmark.peakmem_predict",
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "peakmemory",
        "unit": "bytes",
        "version": "707050e4ebd1a7fea8dc3b127e937aeac112c476b3c0c98283aee9363ab16121"
    },
    "narx.NARXBenchmark.time_fit": {
        "code": "class NARXBenchmark:\n    def time_fit(self, *args):\n        (opt_alg,) = args\n        if opt_alg == \"osa\":\n            coef_init = None\n        else:\n            coef_init = [0] * (self.n_terms_to_select + 1)\n        self.estimator.fit(self.X, self.y, coef_init=coef_init)\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "min_run_count": 2,
        "name": "narx.NARXBenchmark.time_fit",
        "number": 0,
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "1b206f29a096ee3ddaedc7aee7905659967932584527bf9dbe93bfcd9504937e",
        "warmup_time": -1
    },
    "narx.NARXBenchmark.time_predict": {
        "code": "class NARXBenchmark:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X, self.y[: self.max_delay])\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "min_run_count": 2,
        "name": "narx.NARXBenchmark.time_predict",
        "number": 0,
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "repeat": 0,
        "rounds": 2,
        "sample_time": 0.01,
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "time",
        "unit": "seconds",
        "version": "d4ca1c1e924260844dc01e546589313d536a80781a22a58a224ff1c726bea83c",
        "warmup_time": -1
    },
    "narx.NARXBenchmark.track_test_score": {
        "code": "class NARXBenchmark:\n    def track_test_score(self, *args):\n        y_val_pred = self.estimator.predict(\n            self.X_val,\n            self.y_val[: self.max_delay],\n        )\n        return float(r2_score(self.y_val, y_val_pred))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "narx.NARXBenchmark.track_test_score",
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "track",
        "unit": "unit",
        "version": "29d9b2b246daebd2fd99966bd4fcefc4435fadc268d9f9447d9295f23ca794ff"
    },
    "narx.NARXBenchmark.track_train_score": {
        "code": "class NARXBenchmark:\n    def track_train_score(self, *args):\n        y_pred = self.estimator.predict(self.X, self.y[: self.max_delay])\n        return float(r2_score(self.y, y_pred))\n\nclass Benchmark:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, params)\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n\nclass NARXBenchmark:\n    def setup_cache(self):\n        \"\"\"Pickle a fitted estimator for all combinations of parameters\"\"\"\n        # This is run once per benchmark class.\n    \n        param_grid = list(itertools.product(*self.params))\n    \n        for params in param_grid:\n            X, _, y, _ = self.make_data(params)\n            estimator = make_narx(\n                X,\n                y,\n                n_terms_to_select=self.n_terms_to_select,\n                max_delay=self.max_delay,\n                poly_degree=self.poly_degree,\n            )\n    \n            estimator = estimator.fit(X, y, coef_init=\"one_step_ahead\")\n    \n            est_path = get_estimator_path(self, params)\n            with est_path.open(mode=\"wb\") as f:\n                pickle.dump(estimator, f)",
        "name": "narx.NARXBenchmark.track_train_score",
        "param_names": [
            "opt_alg"
        ],
        "params": [
            [
                "'osa'",
                "'msa'"
            ]
        ],
        "setup_cache_key": "narx:24",
        "timeout": 500,
        "type": "track",
        "unit": "unit",
        "version": "bd0a650ee2710599f3dd07b3bf62b0c76b621775fa5fe3ef4f89cdaf8a574398"
    },
    "version": 2
}